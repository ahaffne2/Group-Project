---
title: "Group 8 Project"
authors: "Alex Haffner, Erica Winters & Chris Hargis"
output: pdf_document
---
Our strategy is to use a multivariate logistic regression model that is easy to build and maintain. The purpose of this model will be to predict and classify customers that will churn or will not churn. This model can use a few, several or all the variables from a given dataset to return a binary output. This strategy will work well because we can determine the important criteria for customer churn for your business then create the model that will return the necessary binary output needed for the companyâ€™s insights. 

```{r}

df = read.csv("C:/Users/charg/Desktop/Masters/Churn_Train.csv")
df_test = load("C:/Users/charg/Desktop/Masters/Customers_To_Predict.RData")


```

See the ratio of the target variable "churn". We can see here that we have enough variability of the target variable

```{r}
table(df$churn)
```

Checking for NAs. 
```{r}
summary(df)
```

Removing the NA values

```{r}
library(tidyr)

df = df[!is.na(df$number_vmail_messages),]
df = df[!is.na(df$account_length),]
df = df[!is.na(df$total_eve_minutes),]
df = df[!is.na(df$total_intl_calls),]

table(df$churn)

```


Using random forest to see the importance of the variables. The higher the value the more important. 

```{r}
#install.packages("randomForest")
library(randomForest)

df$churn <- as.factor(df$churn)

output.forest1 = randomForest(churn ~ account_length + number_vmail_messages + total_day_minutes + total_day_calls + total_day_charge +
                                total_eve_minutes + total_eve_calls + total_eve_charge + total_night_minutes + total_night_calls +
                                total_night_charge + total_intl_minutes + total_intl_calls + total_intl_charge + number_customer_service_calls
                              + international_plan + voice_mail_plan + state + area_code, data = df)
randomForest::importance(output.forest1)

```

Another method to visually see the important variables. This will be important
as it will tell us which variables to use in our model. Using all the variables
can result to overfitting. 

```{r}
varImpPlot(output.forest1)
```


Create training and test sample sets:

Create Training Set:
```{r}
no_churn_df = df[which(df$churn == "no"), ]
yes_churn_df = df[which(df$churn == "yes"), ]

```

Create training set to 75% of data
```{r}
set.seed(115)
training_data_1 = sample(1:nrow(no_churn_df), 0.01*nrow(no_churn_df))
training_data_2 = sample(1:nrow(yes_churn_df), 0.01*nrow(yes_churn_df))

training_1 = no_churn_df[training_data_1, ]
training_2 = yes_churn_df[training_data_2, ]

training_data = rbind(training_1, training_2)

```


Creating the Test Set
```{r}
test_1 = no_churn_df[-training_data_1, ]    #the opposite of what the training data was
test_2 = yes_churn_df[-training_data_2, ]

test_data = rbind(test_1, test_2)

```


Building the Model

We are using the top variable "total_day_charge". We discovered through examining the results
of the AIC/BIC and confusion matrix efficiency that using only 1 variable yielded the 
most accurate score. 

```{r}
model = glm(churn ~ total_day_charge, data = training_data, family = binomial(link = "logit"))
```

Using the test data for predictions
```{r}
predicted = predict(model, test_data)

test_data$Predicted = predicted    #adding predictions to data

```

Evaluating the model
```{r}
model_summary = summary(model)
model_summary$coefficients
```

Akaike's & Bayesian Information Criteria. We want these to be as low as possible. (Under 100)

```{r}
paste0("Akaike's score: ", round(AIC(model), 0))
paste0("Bayesian's score: ", round(BIC(model), 0))
            
```

Seeing the P-value for total_day_charge. It is not statistically significant given
its not under .05 however we have support from the forest chart and from testing that
this variable is the most significant. 

```{r}
anova(model, test = "Chisq")
```


Creation of a Confusion Matrix for the training data
```{r}
training_data$Predict = ifelse(model$fitted.values > 0.50, "yes", "no")
table1 = table(training_data$churn, training_data$Predict)
rownames(table1) = c("Observed negative", "Observed positive")
colnames(table1) = c("Predicted negative", "Predicted positive")
table1

```

Checking the efficiency of our training confusion matrix
```{r}
efficieny = sum(diag(table1))/sum(table1)
efficieny
```
Predicting values back on the original data set
```{r}
pred = predict(model, df, "link")
head(pred)
```
Creation of a Confusion matrix for the full data set
```{r}
df$Class = ifelse(pred > 0, "yes", "no")
```

Displaying the Confusion matrix for the model results on the original data
```{r}
#install.packages("yardstick")
#install.packages("ggplot2")
library(yardstick)
library(ggplot2)

truth <- data.frame(
  obs = df$churn,
  pred1 = df$Class)

truth$obs <- as.factor(truth$obs)
truth$pred1 <- as.factor(truth$pred1)

cm <- conf_mat(truth, obs, pred1)

autoplot(cm, type = "heatmap") +
  scale_fill_gradient(low="#D6EAF8",high = "#2E86C1") + theme(legend.position = "right")
```

```{r}
table2 = table(df$churn, df$Class)
rownames(table2) = c("Observed negative", "Observed positive")
colnames(table2) = c("Predicted negative", "Predicted positive")
efficieny2 = sum(diag(table2))/sum(table2)
efficieny2
```



```{r}


```